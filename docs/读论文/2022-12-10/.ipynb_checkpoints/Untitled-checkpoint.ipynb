{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0a4828",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./title.png)\n",
    "- 本文提出了HIP-NN模型，用量化计算数据建模分子性质。\n",
    "- 并且可以将分子属性，例如能量，分解成求和项。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a9283c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./fig1.png\" align=\"left\" width=\"35%\"></img>\n",
    "<div>\n",
    "    <li>绿色是相互作用层interaction，从周围原子获取信息，有两个</li>\n",
    "    <li>红色的是on-site layer，每组有三层</li>\n",
    "    <li>蓝色是每一层的能量</li>\n",
    "    <li>原子特征有80个</li>\n",
    "使用theano框架\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b39c2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A 原子表达\n",
    "分子的构型可以用$\\mathcal{C}=\\{(Z_i,r_i)\\}$表达,$Z_i$是原子序数，$r_i$是原子坐标，但使用原子间距$r_{ij}=|r_i-r_j|$\n",
    "\n",
    "相邻原子条件$r_{ij}<R_{cut}$\n",
    "\n",
    "使用独热向量表示$Z_i$\n",
    "\n",
    "$z_{i,a}^0=\\delta_{Z_i},\\mathcal{Z}_{a}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a344d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## B 原子特征和能量\n",
    "原子特征：$z_{i,a}^l$\n",
    "\n",
    "$l$是层索引；$a$是特征索引；$i$是原子索引\n",
    "\n",
    "输入特征向量：$z_i^0$\n",
    "\n",
    "下一层的特征：$z_i^{l+1}$是基于上一层相邻原子的特征得来的$(z_j^l,r_{ij})$\n",
    "\n",
    "$\\hat{E}_i^n=\\sum_{a=1}^{N_{feature}}w_a^nz_{i,a}^{l_n}+b^n $\n",
    "\n",
    "$w_a^n和b^n是学习参数$，总能量：$E\\approx \\hat{E}=\\sum _{i=1}^{N_{atom}}\\hat{E}_i$\n",
    "\n",
    "$\\hat{E}_i=\\sum _{n=0}^{N_{interaction}}\\ \\hat{E}_i^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3abb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## C On-site layers\n",
    "on-site layer操作每一个原子特征\n",
    "\n",
    "$\\tilde{z}_{i,a}^{l+1}=f( \\sum_{b}W_{ab}^lz_{i,b}^l+B_a^l )$\n",
    "\n",
    "$W,B$是学习参数，$f$是激活函数 $f(x)=log(1+e^x)$\n",
    "\n",
    "使用残差网络\n",
    "\n",
    "$z_{i,a}^{l+1}=\\sum_{b}(\\tilde{W} _{ab}^l\\tilde{z}_{i,b}^{l+1}+M_{ab}^lz_{i,b}^l)+\\tilde B_a^l$\n",
    "\n",
    "$W,M,B$都是学习参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a21131",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## D 相互作用层\n",
    "$\\tilde z_{i,a}^{l+1}=f(\\sum_{j,b}v _{ab}^l(r_{ij})z_{j,b}^l+\\sum_{b}W _{ab}^l\\tilde{z}_{i,b}^l+B_a^l) \\tag{8}$\n",
    "\n",
    "$v _{ab}^l(r_{ij})$是从相邻原子收集到的信息。\n",
    "\n",
    "$v _{ab}^l(r_{ij})=\\sum_{\\nu }V_{\\nu,ab}^ls_\\nu^l(r_{ij}) \\tag{9}$\n",
    "\n",
    "$V$是学习参数，s是空间灵敏度参数，有20个$\\nu$\n",
    "\n",
    "$s_\\nu^l(r_{ij})=exp\\left [ -\\frac{(r^{-1}-\\mu_{\\nu,l}^{-1})^2}{2\\sigma _{\\nu,l}^{-2}}\\right]\\varphi _{cut}(r) \\tag{10}$\n",
    "\n",
    "$\\mu_{\\nu,l}$和$\\sigma _{\\nu,l}$是学习参数，$R_{cut}$从1.7到10bohr\n",
    "\n",
    "$\\varphi _{cut}(r)=\\left\\{\\begin{matrix}\n",
    " \\left [ \\cos (\\frac{\\pi}{2}\\frac{r}{R_{cut}}  ) \\right ]^2  & r\\le R_{cut} \\\\\n",
    " 0 & r\\ge  R_{cut}\n",
    "\\end{matrix}\\right. \\tag{11}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39423290",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 损失函数\n",
    "$\\mathcal{L}=\\frac{1}{\\sigma _E}(MAE+RMSE)+\\mathcal{L}_{L2}+\\mathcal{L}_R \\tag{14}$\n",
    "\n",
    "$\\sigma _E=\\sqrt[]{\\left \\langle (E-\\left \\langle E \\right \\rangle )^2 \\right \\rangle }_D \\tag{15}$\n",
    "\n",
    "$\\mathcal{L}_{L2}=\\lambda _{L2}\\left ( \\frac{||w||_2^2}{\\sigma _E^2} + ||W||_2^2+||V||_2^2+||\\tilde W||_2^2+||\\tilde M||_2^2\\right) \\tag{16}$\n",
    "\n",
    "其中$\\lambda _{L2}$是一个很小的超参数，能够减小结果的偏离程度\n",
    "\n",
    "$\\mathcal{L}_R=\\lambda _R\\left \\langle R \\right \\rangle _D \\tag{17}$\n",
    "\n",
    "为了增加能量项的层次加入的\n",
    "\n",
    "$R=\\sum _{n=1}^{N_{interaction}}\\sum _{i=1}^{N_{atom}}\\frac{(\\hat{E}_i^n)^2}{(\\hat{E}_i^n)^2+(\\hat{E}_i^{n-1})^2} \\tag{18}$\n",
    "\n",
    "正常情况下能量会迅速衰减，当R比较大的时候，说明模型不正常"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ad3e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 随机优化\n",
    "使用`Adam`优化器\n",
    "\n",
    "用$U=\\{w,b,W,B,V,\\sigma ,\\mu ,\\hat{W},\\hat{B},\\hat{M}\\}$表达模型参数\n",
    "\n",
    "用测试集的损失打分(bset_score)，分数不变时减小学习率，分数减小停止训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420740f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 讨论\n",
    "在QM9和MD轨迹都有很好的表现。\n",
    "\n",
    "有以下原因：\n",
    "\n",
    "1. 使用灵敏度函数，使用距离导数作为参数。短范围内高灵敏度，长范围低灵敏度。\n",
    "2. 使用ResNet\n",
    "\n",
    "少量的L2正则化(Eq.(16))对有助于稳定均方根误差，且对MAE的影响很小。\n",
    "\n",
    "能量分层的机制提升了HIPNN的表现。\n",
    "\n",
    "缺点时预测的能量有些方面预测误差还是比较大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31784c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
